{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f00b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob as gg\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm as cm\n",
    "from matplotlib import rc as rc\n",
    "#\n",
    "from netCDF4 import Dataset  \n",
    "#\n",
    "from datetime import datetime,date\n",
    "#\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ebca4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_daily=True # set to - True for daily grid output (early preprocessing steps) \n",
    "                # or \n",
    "                #        - False according to the simulation setting and corresponding forcing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f163b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# load time properties\n",
    "#\n",
    "class REcoM_time:\n",
    "    def __init__(self, flag_daily):\n",
    "        # load time properties\n",
    "        self.estimate_time_axis(flag_daily)\n",
    "    def estimate_time_axis(self, flag_daily):\n",
    "        path_obs = '/home/fbirrien/NuArctic/nuarctic/REcoM1D/config/'\n",
    "        filename = path_obs + 'time.recom'\n",
    "        # read data\n",
    "        with open(filename) as f:\n",
    "            lines = f.readlines()\n",
    "        for l in lines:\n",
    "            tmp = l.replace(' ','').replace('\\t','').split('=')[-1].strip()\n",
    "            if 'start_date' in l:\n",
    "                date_start = datetime.strptime(tmp,'%d-%m-%Y').toordinal()\n",
    "            elif 'end_date' in l:\n",
    "                date_end = datetime.strptime(tmp,'%d-%m-%Y').toordinal()\n",
    "            elif 'dt' in l:\n",
    "                dt = float(tmp)/24.\n",
    "            elif 'spinup' in l:\n",
    "                spinup = int(tmp)\n",
    "            if flag_daily:\n",
    "                dt, spinup = 1., 0\n",
    "        self.date_start, self.date_end = np.copy(date_start), np.copy(date_end)\n",
    "        \n",
    "        # account for spinup\n",
    "        date_start = date_start - spinup\n",
    "        \n",
    "        # create time axis\n",
    "        npt = int(abs(date_end - date_start)/dt)\n",
    "        self.dates = np.linspace(date_start, date_end, npt+1)        \n",
    "#\n",
    "recom_dates = REcoM_time(flag_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a341a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh type\n",
    "mesh_type='farc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dbf9288",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_input='/home/fbirrien/NuArctic/nuarctic/REcoM1D/grid/'\n",
    "path_input_mesh=path_input + '/mesh/' + mesh_type + '/'\n",
    "path_input_track=path_input + 'track/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8d79a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# load vertical mesh\n",
    "#\n",
    "class vertical_mesh(object):\n",
    "    def __init__(self, filename):\n",
    "        self.read_vertical_mesh(filename)\n",
    "    def read_vertical_mesh(self,filename):\n",
    "        data = np.asarray(pd.read_csv(filename,header=None))\n",
    "        self.nl = int(data[0])\n",
    "        self.zbar = np.reshape(data[1:self.nl+1], len(data[1:self.nl+1]))\n",
    "        self.Z = 0.5*(self.zbar[1:] + self.zbar[:-1])\n",
    " #       \n",
    "filename=path_input_mesh + 'aux3d.out'\n",
    "vmesh = vertical_mesh(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cefbcbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# load MOSAiC track\n",
    "#\n",
    "class MOSAiC_track(object):\n",
    "    def __init__(self,filename, data):\n",
    "        self.read_MOSAiC_track(filename, data)\n",
    "    def read_MOSAiC_track(self,filename, data):\n",
    "        # open nc file\n",
    "        ncid = Dataset(filename, \"r\", format=\"NETCDF4\")        \n",
    "\n",
    "        # read dates and geo coordinates\n",
    "        dates = ncid.variables['dates'][:]\n",
    "        longitude, latitude = ncid.variables['longitude'][:], ncid.variables['latitude'][:]\n",
    "        if 'depth' in ncid.variables:\n",
    "            depth = ncid.variables['depth'][:]\n",
    "        # close nc file\n",
    "        ncid.close()\n",
    "        # crop data to time frame\n",
    "        ind1, ind2 = np.where(dates>=data.date_start)[0], np.where(dates<=data.date_end)[0]\n",
    "        indices = list(set(ind1) & set(ind2))\n",
    "        # store data\n",
    "        self.dates, self.depth = dates[indices], depth[indices]\n",
    "        self.longitude, self.latitude = longitude[indices], latitude[indices]\n",
    "#\n",
    "#filename = path_input_track + 'Polarstern_trajectory.nc'\n",
    "filename = path_input_track + 'MOSAiC_Icetrack_trajectory.nc'\n",
    "track=MOSAiC_track(filename, recom_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a74bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# load mesh + depth (truncated in the high latitude)\n",
    "#\n",
    "class Mesh(object):\n",
    "    def __init__(self,path,latmin):\n",
    "        self.read_mesh(path)\n",
    "        self.read_depth(path)\n",
    "        self.truncate_mesh(latmin)\n",
    "    def read_mesh(self,path):\n",
    "        filename=path+'nod2d.out'\n",
    "        data = pd.read_csv(filename, sep='\\s+', skiprows=1 , header=None)\n",
    "        self.longitude, self.latitude = data.iloc[:,1], data.iloc[:,2]\n",
    "    def read_depth(self,path):\n",
    "        filename=path+'aux3d.out'\n",
    "        data = np.asarray(pd.read_csv(filename,header=None))\n",
    "        nb = int(data[0])\n",
    "        self.depth = data[nb+1:]\n",
    "    def truncate_mesh(self,latmin):\n",
    "        indices=np.where(self.latitude>=latmin-0.5)[0]\n",
    "        self.longitude, self.latitude, self.depth = self.longitude[indices], self.latitude[indices], self.depth[indices]\n",
    "                 \n",
    "mesh=Mesh(path_input_mesh, np.min(track.latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d58a50f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# estimate depth along the MOSAiC trajectory\n",
    "#\n",
    "def tunnel_distance_nearest_neighbor_index(lon, lat, longitude_ref, latitude_ref):\n",
    "    #\n",
    "    # estimate nearest neighbor of (lon,lat) point and return point index\n",
    "    #\n",
    "    # convert lon, lat to radian\n",
    "    deg2rad = np.pi / 180.0\n",
    "    lon, lat, longitude_ref, latitude_ref =  deg2rad*lon, deg2rad*lat , deg2rad*longitude_ref, deg2rad*latitude_ref\n",
    "    \n",
    "    #compute cos,sin and cross-products for of the different a lon,lat arrays\n",
    "    # grid\n",
    "    clat, clon, slat, slon = np.cos(lat), np.cos(lon), np.sin(lat), np.sin(lon)\n",
    "    clat_clon,  clat_slon = clat * clon, clat * slon\n",
    "    \n",
    "    # reference node\n",
    "    clat_ref, clon_ref, slat_ref, slon_ref = np.cos(latitude_ref), np.cos(longitude_ref), np.sin(latitude_ref), np.sin(longitude_ref)\n",
    "    clat_clon_ref,  clat_slon_ref = clat_ref * clon_ref, clat_ref * slon_ref\n",
    "    \n",
    "    # compute tunnel distance to the different grid nodes\n",
    "    distance = []\n",
    "    dX, dY, dZ = clat_clon - clat_clon_ref, clat_slon - clat_slon_ref, slat - slat_ref\n",
    "    distance = dX**2 + dY**2 + dZ**2\n",
    "\n",
    "    return np.argmin(distance)\n",
    "# \n",
    "class Complete_track_data(object):\n",
    "    def __init__(self, track, mesh):\n",
    "        #data\n",
    "        self.dates, self.longitude, self.latitude = track.dates, track.longitude, track.latitude\n",
    "        # estimate depth\n",
    "        self.estimate_depth(mesh)\n",
    "        \n",
    "    def estimate_depth(self,mesh):\n",
    "        depth=[]\n",
    "        for i in range(len(self.dates)):\n",
    "            lon, lat = self.longitude[i],self.latitude[i]\n",
    "            index=tunnel_distance_nearest_neighbor_index(mesh.longitude, mesh.latitude, lon, lat)\n",
    "            depth.append(mesh.depth[index])\n",
    "        depth=np.asarray(depth)\n",
    "        self.depth = np.reshape(depth, depth.size)\n",
    "        \n",
    "new_track=Complete_track_data(track,mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0ef03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# include nb of levels in use at each track point \n",
    "#\n",
    "class vertical_track(object):\n",
    "    def __init__(self,track, vmesh):\n",
    "        self.dates, self.longitude, self.latitude, self.depth = track.dates, track.longitude, track.latitude, track.depth\n",
    "        self.estimate_nb_of_level(vmesh)\n",
    "    def estimate_nb_of_level(self,vmesh):\n",
    "        # compare depth\n",
    "        nlevels=[]\n",
    "        for dpth in self.depth:\n",
    "            nlevels.append(np.where(vmesh.zbar - dpth <0)[0][0])\n",
    "        self.nlevels = np.asarray(nlevels)\n",
    "#\n",
    "track_data = vertical_track(new_track,vmesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c46f7979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# estimate coordinate, depth and level at each simulation time using MOSAiC track observations and manage spinup\n",
    "#\n",
    "class simulation_data:\n",
    "    def __init__(self, recom_dates, vmesh, track):\n",
    "        self.dates = recom_dates.dates\n",
    "        self.nl, self.zbar, self.Z = vmesh.nl, vmesh.zbar, vmesh.Z\n",
    "        # estimate coordinates, depth and \n",
    "        self.estimate_simulation_mesh_characteristics(recom_dates, track)\n",
    "        \n",
    "    def estimate_simulation_mesh_characteristics(self, recom_dates, track):\n",
    "        #initialization\n",
    "        lon, lat, dpth, nlvl = [], [], [], []\n",
    "        # simulation part without spin up\n",
    "        var = recom_dates\n",
    "        ind1, ind2 = np.where(var.dates>=var.date_start)[0], np.where(var.dates<=var.date_end)[0]\n",
    "        indices = list(set(ind1) & set(ind2))\n",
    "        \n",
    "        date = var.dates[indices]\n",
    "        \n",
    "        for dt in date:    \n",
    "            # look for corresponding dates\n",
    "            index = np.argmin(abs(track.dates-dt))\n",
    "            lon.append(track.longitude[index]), lat.append(track.latitude[index])\n",
    "            dpth.append(track.depth[index]), nlvl.append(track.nlevels[index])\n",
    "            # store data\n",
    "        long, lati, dept, nlev = np.asarray(lon), np.asarray(lat), np.asarray(dpth), np.asarray(nlvl)\n",
    "        \n",
    "        # manage spin up and store data\n",
    "        npt = len(var.dates)\n",
    "        # spinup (fill with initial conditions)\n",
    "        longitude, latitude = np.zeros(npt) + long[0], np.zeros(npt) + lati[0]\n",
    "        depth, nlevels = np.zeros(npt) + dept[0], np.zeros(npt) + nlev[0]\n",
    "        # actual simulation\n",
    "        longitude[indices], latitude[indices] = long, lati\n",
    "        depth[indices], nlevels[indices] = dept, nlev\n",
    "        \n",
    "        # store data\n",
    "        self.longitude, self.latitude, self.depth, self.nlevels = longitude, latitude, depth, nlevels\n",
    "#\n",
    "simu_data = simulation_data(recom_dates,vmesh, track_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbda2018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Output at 0x7f31c099baf0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# save data to netcdf file\n",
    "#\n",
    "class Output(object):\n",
    "    def __init__(self, filename, data):\n",
    "        self.write_grid_information(filename,data)\n",
    "        \n",
    "    def write_grid_information(self,filename,data):\n",
    "        # store grid (Lagrangian and vertical) information\n",
    "        ncid = Dataset(filename, \"w\", format=\"NETCDF4\") \n",
    "\n",
    "        ## define dimensionss\n",
    "        ncid.createDimension('time', len(data.dates))\n",
    "        ncid.createDimension('nl', data.nl)\n",
    "        ncid.createDimension('nl1', data.nl-1)\n",
    "        dimnl, dimnl1, dimt = ('nl'), ('nl1'), ('time')\n",
    "\n",
    "        ## create variables\n",
    "        # dates\n",
    "        dt = ncid.createVariable('dates', \"f8\",'time')\n",
    "        \n",
    "        # geo coordinates\n",
    "        lon, lat = ncid.createVariable('longitude', \"f8\",'time'), ncid.createVariable('latitude', \"f8\",'time')\n",
    "        \n",
    "        # vertical mesh\n",
    "        zb, z = ncid.createVariable('zbar', \"f8\",'nl'), ncid.createVariable('Z', \"f8\",'nl1')\n",
    "        \n",
    "        # related depth and number of vertical levels along the track\n",
    "        dpth, nlvl = ncid.createVariable('depth', \"f8\",'time'), ncid.createVariable('nlevels', \"f8\",'time')\n",
    "        \n",
    "        \n",
    "        ## variables attributes\n",
    "        # description\n",
    "        dt.description='dates related to python ordinal dates (reference date 01/01/0001)'\n",
    "        lon.description, lat.description = 'longitude coordinates', 'latitude coordinates'\n",
    "        zb.description, z.description = 'vertical discretization of depth axis (from ' + mesh_type + ' mesh)', 'vertical discretization of depth axis (middle of cells)'\n",
    "        dpth.description, nlvl.description = 'depth (from topography)', 'number of level considered in simulation (according to depth)'\n",
    "        # units\n",
    "        dt.units='days'\n",
    "        lon.units, lat.units = 'degree (east)', 'degree (north)'\n",
    "        zb.units, z.units = 'm', 'm'\n",
    "        dpth.units, nlvl.units = 'm', ''        \n",
    "        \n",
    "        ## fill variables\n",
    "        # dates\n",
    "        ncid['dates'][:] = data.dates\n",
    "        \n",
    "        # geo coordinates\n",
    "        ncid['longitude'][:] , ncid['latitude'][:] =  data.longitude, data.latitude\n",
    "        \n",
    "        # vertical mesh\n",
    "        ncid['zbar'][:] , ncid['Z'][:] = data.zbar, data.Z\n",
    "        \n",
    "        # depth and vertical levels along the track\n",
    "        ncid['depth'][:] , ncid['nlevels'][:] = data.depth, data.nlevels\n",
    "        \n",
    "        #\n",
    "        ncid.close()\n",
    "\n",
    "#\n",
    "filename = path_input + 'REcoM1D_daily_mesh.nc' if flag_daily else path_input + 'REcoM1D_mesh.nc'\n",
    "Output(filename, simu_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f82b53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
