{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prescription-performer",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyfesom2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5718/3952359149.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyfesom2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnetCDF4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyfesom2'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "scripts to extract REcoM-related variables from FESOM runs\n",
    "\n",
    "\"\"\"\n",
    "#\n",
    "import os\n",
    "import argparse\n",
    "from glob import glob as gg\n",
    "#\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "#\n",
    "import pyfesom2 as pf\n",
    "#\n",
    "from netCDF4 import Dataset \n",
    "#\n",
    "import pickle\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dried-front",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOSAIC trajectory dates and coordinates\n",
    "class Trajectory:\n",
    "  def __init__(self, filename):\n",
    "    # read MOSAiC trajectory data\n",
    "    self.read_trajectory(filename)\n",
    "    # month & year information\n",
    "    self.dates_information()\n",
    "  \n",
    "  def read_trajectory(self,filename):\n",
    "    ncid = Dataset(filename, \"r\", format=\"NETCDF4\")\n",
    "    # read dates/work/ollie/fbirrien/trajectories\n",
    "    self.dates = ncid.variables['dates'][:]\n",
    "    # read coordinates\n",
    "    self.longitude, self.latitude = ncid.variables['longitude'][:], ncid.variables['latitude'][:]\n",
    "    ncid.close()\n",
    "\n",
    "  def dates_information(self):\n",
    "    # store month & year information along the track\n",
    "    month, year = [], []\n",
    "    for dt in self.dates:\n",
    "      tmp=datetime.fromordinal(int(dt)) \n",
    "      month.append(tmp.month), year.append(tmp.year)\n",
    "    self.month, self.year = np.asarray(month), np.asarray(year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "appointed-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read or extract nodes in the FESOM mesh which correspond to the MOSAiC transect\n",
    "def load_nodes(path, data):\n",
    "  filename_nodes = path_mesh + 'pickle_MOSAiC_transect'\n",
    "  # look if nodes corresponding to MOSAiC trajectory has been store in a pickle file\n",
    "  if os.path.exists(filename_nodes):\n",
    "    print('The pickle file with MOSAiC mesh nodes exists, nodes with be loaded from this file')\n",
    "    # load pickle file\n",
    "    input_file = open(filename_nodes, \"rb\")\n",
    "    nodes = pickle.load(input_file)\n",
    "    input_file.close()\n",
    "    \n",
    "  else:\n",
    "    print('The pickle file with MOSAiC mesh nodes does not exist but will be created')\n",
    "    # extract transect and store data as pickle file\n",
    "    lonlat = np.vstack((data.longitude, data.latitude))\n",
    "    nodes = pf.transect_get_nodes(lonlat,mesh)\n",
    "    output_file = open(filename_nodes, \"wb\")\n",
    "    pickle.dump(nodes, output_file)\n",
    "    output_file.close()\n",
    "\n",
    "  return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "regular-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the output time axis from the FESOM runs\n",
    "def get_time(result_path, variable, years, runid=\"fesom\", records=-1,ncfile=None, naming_convention=\"fesom\", naming_template=None):\n",
    "    \"\"\"\n",
    "    Get  output time from files.\n",
    "    Parameters\n",
    "    ----------\n",
    "    result_path : string\n",
    "        path to the data folder.\n",
    "    variable : string\n",
    "        variable name\n",
    "    years : int, list\n",
    "        year or list of years to open\n",
    "    records: int, slice, list\n",
    "        number of time steps to be considered for aggregation.\n",
    "        If -1 (default), all timesteps will be taken in to account.\n",
    "        If 0, only the first record will be taken\n",
    "        If [0,5,7], only time steps with indexes 0,5 and 7 will be taken\n",
    "        If slice(2,120,12), every 12th time step starting from the third one will be selected.\n",
    "    depth: float\n",
    "        The model depth closest to provided depth will be taken.\n",
    "        If None, 3d field will be returned. Default = None.\n",
    "    ncfile: str\n",
    "        if provided, the netCDF file will be opened directly.\n",
    "        Some dummy data have to be provided for result_path and years\n",
    "    runid: str\n",
    "        For esm-tools naming convention, use the experiment id name (e.g. test, PI-CTRL, LGM, ...)\n",
    "    naming_convention : str\n",
    "        The naming convention to be used. Can either be \"fesom\" for classic\n",
    "        infrastructure, \"esm-tools\" for esm-tools infrastructure, or \"custom\",\n",
    "        in which case a template string must be provided.\n",
    "     naming_template : None or str\n",
    "        Required if a customized naming convention is to be used. Replaced variables will be (in order) variable, runid, year.\n",
    "     \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data: xarray\n",
    "       time.\n",
    "    \"\"\"\n",
    "    paths = []\n",
    "    if ncfile:\n",
    "        paths = ncfile\n",
    "    elif isinstance(years, int):\n",
    "        if naming_convention == \"fesom\":\n",
    "            fname = \"{}.{}.{}.nc\".format(variable, runid, years)\n",
    "        elif naming_convention == \"esm_tools\":\n",
    "            fname = f\"{runid}.{years}.{variable}01.01.nc\"\n",
    "        elif naming_convention == \"custom\":\n",
    "            fname = naming_template.format(variable, runid, years)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"You must have fesom, esm_tools, or custom as naming_convention!\"\n",
    "            )\n",
    "        paths = os.path.join(result_path, fname)\n",
    "    else:\n",
    "        raise ValueError(\"year can be integer, list or one dimentional numpy array\")\n",
    "\n",
    "    dataset = xr.open_mfdataset(paths, combine=\"by_coords\")\n",
    "    time_data = np.asarray(dataset['time'])\n",
    "\n",
    "    # transform time to python ordinal time  \n",
    "    dates, time = [], []\n",
    "    for t in time:\n",
    "      tmp = datetime.strptime(str(t).split('.')[0], '%Y-%m-%dT%H:%M:%S')\n",
    "      dates.append(tmp), time.append(tmp.toordinal())\n",
    "    return np.asarray(dates), np.asarray(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "preceding-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FESOM output variables\n",
    "class FESOM_variables:\n",
    "  def __init__(self, filename, mesh):\n",
    "    path_output = '/'.join(filename.split('/')[:-1])\n",
    "    self.varname, self.year = filename.split('.')[0].split('/')[-1], int(filename.split('.')[-2])\n",
    "   \n",
    "    # extract output variable\n",
    "    self.extract_variable(path_output, mesh)  \n",
    "    \n",
    "    # extract time\n",
    "    self.extract_time(path_output)\n",
    "\n",
    "  def extract_variable(self, path_output, mesh):\n",
    "    # extract variable on user-defined mesh\n",
    "    self.var = pf.get_data(path_output, self.varname, self.year, mesh, how='ori', compute=False) \n",
    "\n",
    "  def extract_time(self, path_output):\n",
    "    # extract associated output time (python ordinal dates)\n",
    "    self.dates = get_time(path_output, self.varname, self.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "authorized-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define list of output to extract transect from\n",
    "def define_list_of_output_files(path):\n",
    "  # variable of interest\n",
    "  var_name = ['a_ice', 'Alk', 'benC', 'benN', 'benSi', 'pCO2','DetCalc', 'DetC', 'DetN', 'DetSi', 'DFe' , 'DiaC', 'DiaChl', 'DiaN', 'DiaSi', 'DIC', 'DIN', 'DOC' , 'DON' , 'HetC', 'HetN', 'idetz2calc', 'idetz2c', 'idetz2n', 'idetz2si', 'Kv', 'O2', 'PAR', 'pCO2s', 'PhyCalc', 'PhyC', 'PhyChl', 'PhyN', 'runoff', 'salt', 'temp', 'u', 'uice', 'v','vice','w', 'Zoo2C', 'Zoo2N']\n",
    "\n",
    "  var_name = ['a_ice']\n",
    "  # list of output file o be processed\n",
    "\n",
    "  for vr in var_name:\n",
    "    nm = vr +'.fesom.'\n",
    "    try:\n",
    "      filelist=np.hstack((filelist, gg(path + nm + '*')))\n",
    "    except:\n",
    "      filelist = gg(path + vr + '*')\n",
    "  return filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "marine-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction of FESOM output along the track on the daily/weekly/monthly basis\n",
    "# monthly outputs\n",
    "def extract_daily_transect_data_from_monthly_outputs(output, month, nodes):\n",
    "  # extract daily data along the MOSAiC track from monthly FESOM outputs\n",
    "  dates, dim = trajectory.dates, len(output.shape)\n",
    "  for i, mnth in enumerate(month):\n",
    "    # extract output along the track for the selected year\n",
    "    tmp = output[int(mnth)-1, nodes[i],:] if dim>2 else output[int(mnth)-1, nodes[i]]\n",
    "    transect = xr.concat([transect,tmp],dim='time') if i>0 else tmp\n",
    "  return transect\n",
    "\n",
    "\n",
    "# daily outputs\n",
    "def change_time_axis(xarray, dates):\n",
    "  # convert ordinal track-related dates to string\n",
    "  times=[]\n",
    "  for i, dt in enumerate(dates):\n",
    "    tmp = datetime.fromordinal(int(dt))\n",
    "    tmp = tmp.replace(hour=int(np.round(24.*(dt-float(int(dt))))))\n",
    "    #tmp = datetime.strftime(tmp, '%Y-%m-%d %H:%M:%S')\n",
    "    times = np.hstack((times,tmp)) if i>0 else tmp\n",
    "  # change time values in xarray\n",
    "  xarray['time'] = times\n",
    "  return xarray\n",
    " \n",
    "# extraction main routine\n",
    "def extract_transect_outputs(fesom_outputs, trajectory_data, nodes, output_frequency='daily'):\n",
    "\n",
    "  # extract FESOM outputs along the MOSAiC transect\n",
    "  \n",
    "  # initialization, crop trajectory dates according to the output year (cf. FESOM outputs)   \n",
    "  var, year_output = fesom_outputs.var, fesom_outputs.year\n",
    "  dates, year, month = trajectory_data.dates, trajectory_data.year, trajectory_data.month\n",
    "  indices = np.where(year==year_output)[0]\n",
    "  dates, nodes, month = dates[indices], nodes[indices], month[indices]\n",
    "\n",
    "  # extract transect outputs\n",
    "  if  var.shape[0]>12:\n",
    "    print('daily FESOM outputs to be processed')\n",
    "    if 'daily' in output_frequency:\n",
    "      print('not coded yet') \n",
    "      transect_output = []\n",
    "    elif 'monthly' in output_frequency:\n",
    "      print('not coded yet')\n",
    "      transect_output = []\n",
    "  else:\n",
    "    print ('monthly FESOM outputs to be processed')\n",
    "    if 'daily' in output_frequency:\n",
    "      # extract transect data\n",
    "      transect_output = extract_daily_transect_data_from_monthly_outputs(var, month, nodes)\n",
    "      # change time axis\n",
    "      transect_output = change_time_axis(transect_output, dates)\n",
    "    elif 'monthly' in output_frequency:\n",
    "      print ('not coded yet')\n",
    "      transect_output = []\n",
    "  return transect_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alleged-shade",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5718/3980234842.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpath_trajectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/work/ollie/fbirrien/trajectories/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfilename_trajectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_trajectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'MOSAiC_track_20191005_20200731.nc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrajectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_trajectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5718/2180510757.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# read MOSAiC trajectory data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_trajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# month & year information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdates_information\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5718/2180510757.py\u001b[0m in \u001b[0;36mread_trajectory\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mread_trajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mncid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"NETCDF4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# read dates/work/ollie/fbirrien/trajectories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mncid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dates'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#------------------------------------------ \n",
    "# Extraction main script\n",
    "#------------------------------------------\n",
    "#\n",
    "# load MOSAiC trajectory\n",
    "#\n",
    "path_trajectory = '/work/ollie/fbirrien/trajectories/'\n",
    "filename_trajectory = path_trajectory + 'MOSAiC_track_20191005_20200731.nc'\n",
    "trajectory = Trajectory(filename_trajectory)\n",
    "\n",
    "#\n",
    "# load FESOM fArc mesh\n",
    "#\n",
    "path_mesh='/work/ollie/fbirrien/mesh/farc/'\n",
    "mesh = pf.load_mesh(path_mesh, abg=[50,15,-90])\n",
    "\n",
    "#\n",
    "# load mesh point indices that correspond to MOSAiC trajectory\n",
    "#\n",
    "nodes = load_nodes(path_mesh, trajectory)\n",
    "\n",
    "#\n",
    "# extract FESOM outputs along the MOSAiC track (make transects)\n",
    "#\n",
    "# load output\n",
    "path_FESOM='/work/ollie/fbirrien/NuArctic/FESOM_Outputs/'\n",
    "path_output = path_FESOM + 'Outputs/'\n",
    "filelist = define_list_of_output_files(path_output)\n",
    "\n",
    "for filename_FESOM in filelist:\n",
    "  print ('variable & year to be processed', filename_FESOM.split('/')[-1].split('.')[0],  filename_FESOM.split('.')[-2])\n",
    "  fesom_outputs = FESOM_variables(filename_FESOM, mesh)\n",
    "\n",
    "  #\n",
    "  # extract output along the MOSAiC transect\n",
    "  # \n",
    "  transect_outputs = extract_transect_outputs(fesom_outputs, trajectory, nodes)\n",
    "  #\n",
    "  # store transect data\n",
    "  #\n",
    "  filename_transect = filename_FESOM.replace('/Outputs/','/Transects/').replace('.fesom.', '.transect.')\n",
    "  transect_outputs.to_netcdf(filename_transect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-thanks",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
