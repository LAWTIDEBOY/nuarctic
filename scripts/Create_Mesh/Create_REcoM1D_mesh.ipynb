{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f00b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob as gg\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm as cm\n",
    "from matplotlib import rc as rc\n",
    "#\n",
    "from netCDF4 import Dataset  \n",
    "#\n",
    "from datetime import datetime,date\n",
    "#\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ebca4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Parameters, path and filename related to mesh pre-processing\n",
    "#\n",
    "\n",
    "# option to create daily mesh (corresponding to daily average observations) or subhourly/hourly mesh\n",
    "flag_daily=False # set to - True for daily grid output (early preprocessing steps) \n",
    "                # or     - False according to the simulation setting and corresponding forcing \n",
    "    \n",
    "# location and name of the time configuration info file for REcoM simulations (basically define the time frame of the simulation)\n",
    "path_time='../../REcoM1D/config/'\n",
    "filename_time=path_time + 'time.recom'\n",
    "\n",
    "# path general to data\n",
    "path_input='../../data/'\n",
    "\n",
    "# information related to the type of FESOM mesh we are using for the mesh creation, pre-preprocessing and simulation (farc vs core2)\n",
    "# and related path and filename of the mesh\n",
    "mesh_type='farc'\n",
    "path_input_mesh = path_input + 'MESH/mesh/' + mesh_type + '/'\n",
    "filename_mesh_aux = path_input_mesh + 'aux3d.out'\n",
    "filename_mesh_nodes = path_input_mesh + 'nod2d.out'\n",
    "# information related to the MOSAiC track\n",
    "path_input_track=path_input + 'TRACK/'\n",
    "filename_track = path_input_track + 'Polarstern_daily_track.nc'\n",
    "\n",
    "# define output path\n",
    "filename_output = path_input + 'MESH/' + 'REcoM1D_daily_mesh.nc' if flag_daily else path_input + 'MESH/' + 'REcoM1D_mesh.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f163b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# load time information related to the simulation time frame\n",
    "# infos about start date (spinup excluded), end date of the simulation, time step and spinup time (in days)\n",
    "#\n",
    "class REcoM_time:\n",
    "    def __init__(self, filename, flag_daily):\n",
    "        # load time properties\n",
    "        self.estimate_time_axis(filename, flag_daily)\n",
    "    def estimate_time_axis(self, filename, flag_daily):\n",
    "        # read data\n",
    "        with open(filename) as f:\n",
    "            lines = f.readlines()\n",
    "        for l in lines:\n",
    "            tmp = l.replace(' ','').replace('\\t','').split('=')[-1].strip()\n",
    "            # read start date of the simulation\n",
    "            if 'start_date' in l:\n",
    "                date_start = datetime.strptime(tmp,'%d-%m-%Y').toordinal()\n",
    "            # read end date of the simulation\n",
    "            elif 'end_date' in l:\n",
    "                date_end = datetime.strptime(tmp,'%d-%m-%Y').toordinal()\n",
    "            # read time step\n",
    "            elif 'dt' in l:\n",
    "                dt = float(tmp)/24.\n",
    "            # read spinup time\n",
    "            elif 'spinup' in l:\n",
    "                spinup = int(tmp)\n",
    "            if flag_daily:\n",
    "                dt, spinup = 1., 0\n",
    "        self.date_start, self.date_end = np.copy(date_start), np.copy(date_end)\n",
    "        \n",
    "        # estimate starting date accounting for spinup\n",
    "        date_start = date_start - spinup\n",
    "        \n",
    "        # create time axis\n",
    "        npt = int(abs(date_end - date_start)/dt)\n",
    "        self.dates = np.linspace(date_start, date_end, npt+1)        \n",
    "#\n",
    "recom_dates = REcoM_time(filename_time, flag_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8d79a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# load vertical mesh information (from aux3d.out from core2 or farc)\n",
    "#\n",
    "class vertical_mesh(object):\n",
    "    def __init__(self, filename):\n",
    "        self.read_vertical_mesh(filename)\n",
    "    def read_vertical_mesh(self,filename):\n",
    "        data = np.asarray(pd.read_csv(filename,header=None))\n",
    "        # number of depth level\n",
    "        self.nl = int(data[0])\n",
    "        # vertical z at the mesh nodes  \n",
    "        self.zbar = np.reshape(data[1:self.nl+1], len(data[1:self.nl+1]))\n",
    "        # vertical z at the center of cells\n",
    "        self.Z = 0.5*(self.zbar[1:] + self.zbar[:-1])\n",
    " #       \n",
    "vmesh = vertical_mesh(filename_mesh_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cefbcbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# load MOSAiC track\n",
    "#\n",
    "class MOSAiC_track:\n",
    "    def __init__(self,filename, data):\n",
    "        self.read_MOSAiC_track(filename, data)\n",
    "    def read_MOSAiC_track(self,filename, data):\n",
    "        # open nc file\n",
    "        ncid = Dataset(filename, \"r\", format=\"NETCDF4\")        \n",
    "\n",
    "        # read dates and geo coordinates\n",
    "        dates = ncid.variables['dates'][:]\n",
    "        longitude, latitude = ncid.variables['longitude'][:], ncid.variables['latitude'][:]\n",
    "        # close nc file\n",
    "        ncid.close()\n",
    "        # crop data according to simulation time frame\n",
    "        ind1, ind2 = np.where(dates>=data.date_start)[0], np.where(dates<=data.date_end)[0]\n",
    "        indices = list(set(ind1) & set(ind2))\n",
    "        \n",
    "        # store data\n",
    "        self.dates = dates[indices]\n",
    "        self.longitude, self.latitude = longitude[indices], latitude[indices]\n",
    "#\n",
    "#filename = path_input_track + 'Polarstern_trajectory.nc'\n",
    "track=MOSAiC_track(filename_track, recom_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a74bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# load mesh + depth (truncated in the high latitude)\n",
    "#\n",
    "class Mesh:\n",
    "    def __init__(self, filename_aux, filename_nodes, latmin):\n",
    "        self.read_mesh(filename_nodes)\n",
    "        self.read_depth(filename_aux)\n",
    "        self.truncate_mesh(latmin)\n",
    "    # read horizontal mesh node coordinates\n",
    "    def read_mesh(self,filename):\n",
    "        data = pd.read_csv(filename, sep='\\s+', skiprows=1 , header=None)\n",
    "        self.longitude, self.latitude = data.iloc[:,1], data.iloc[:,2]\n",
    "    # read mesh vertical level information (depth at nodes)\n",
    "    def read_depth(self,filename):\n",
    "        data = np.asarray(pd.read_csv(filename,header=None))\n",
    "        nb = int(data[0])\n",
    "        self.depth = data[nb+1:]\n",
    "    # truncate domain according to minimum latitude (to avoid extensive computation cost)\n",
    "    def truncate_mesh(self,latmin):\n",
    "        indices=np.where(self.latitude>=latmin-0.5)[0]\n",
    "        self.longitude, self.latitude, self.depth = self.longitude[indices], self.latitude[indices], self.depth[indices]\n",
    "                 \n",
    "mesh=Mesh(filename_mesh_aux, filename_mesh_nodes, np.min(track.latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58a50f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# estimate depth along the MOSAiC trajectory\n",
    "#\n",
    "def tunnel_distance_nearest_neighbor_index(lon, lat, longitude_ref, latitude_ref):\n",
    "    #\n",
    "    # estimate nearest neighbor of (lon,lat) point and return point index\n",
    "    #\n",
    "    # convert lon, lat to radian\n",
    "    deg2rad = np.pi / 180.0\n",
    "    lon, lat, longitude_ref, latitude_ref =  deg2rad*lon, deg2rad*lat , deg2rad*longitude_ref, deg2rad*latitude_ref\n",
    "    \n",
    "    #compute cos,sin and cross-products for of the different a lon,lat arrays\n",
    "    # grid\n",
    "    clat, clon, slat, slon = np.cos(lat), np.cos(lon), np.sin(lat), np.sin(lon)\n",
    "    clat_clon,  clat_slon = clat * clon, clat * slon\n",
    "    \n",
    "    # reference node\n",
    "    clat_ref, clon_ref, slat_ref, slon_ref = np.cos(latitude_ref), np.cos(longitude_ref), np.sin(latitude_ref), np.sin(longitude_ref)\n",
    "    clat_clon_ref,  clat_slon_ref = clat_ref * clon_ref, clat_ref * slon_ref\n",
    "    \n",
    "    # compute tunnel distance to the different grid nodes\n",
    "    distance = []\n",
    "    dX, dY, dZ = clat_clon - clat_clon_ref, clat_slon - clat_slon_ref, slat - slat_ref\n",
    "    distance = dX**2 + dY**2 + dZ**2\n",
    "\n",
    "    return np.argmin(distance)\n",
    "# \n",
    "class Complete_track_data(object):\n",
    "    def __init__(self, track, mesh):\n",
    "        #data\n",
    "        self.dates, self.longitude, self.latitude = track.dates, track.longitude, track.latitude\n",
    "        # estimate depth\n",
    "        self.estimate_depth(mesh)\n",
    "        \n",
    "    def estimate_depth(self,mesh):\n",
    "        depth=[]\n",
    "        for i in range(len(self.dates)):\n",
    "            lon, lat = self.longitude[i],self.latitude[i]\n",
    "            index=tunnel_distance_nearest_neighbor_index(mesh.longitude, mesh.latitude, lon, lat)\n",
    "            depth.append(mesh.depth[index])\n",
    "        depth=np.asarray(depth)\n",
    "        self.depth = np.reshape(depth, depth.size)\n",
    "        \n",
    "new_track=Complete_track_data(track,mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0ef03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# include nb of levels in use at each track point \n",
    "#\n",
    "class vertical_track(object):\n",
    "    def __init__(self,track, vmesh):\n",
    "        self.dates, self.longitude, self.latitude, self.depth = track.dates, track.longitude, track.latitude, track.depth\n",
    "        self.estimate_nb_of_level(vmesh)\n",
    "    def estimate_nb_of_level(self,vmesh):\n",
    "        # compare depth\n",
    "        nlevels=[]\n",
    "        for dpth in self.depth:\n",
    "            nlevels.append(np.where(vmesh.zbar - dpth <0)[0][0])\n",
    "        self.nlevels = np.asarray(nlevels)\n",
    "#\n",
    "track_data = vertical_track(new_track,vmesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c46f7979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# estimate coordinate, depth and level at each simulation time using MOSAiC track observations and manage spinup\n",
    "#\n",
    "class simulation_data:\n",
    "    def __init__(self, recom_dates, vmesh, track):\n",
    "        self.dates = recom_dates.dates\n",
    "        self.nl, self.zbar, self.Z = vmesh.nl, vmesh.zbar, vmesh.Z\n",
    "        # estimate coordinates, depth and \n",
    "        self.estimate_simulation_mesh_characteristics(recom_dates, track)\n",
    "        \n",
    "    def estimate_simulation_mesh_characteristics(self, recom_dates, track):\n",
    "        #initialization\n",
    "        lon, lat, dpth, nlvl = [], [], [], []\n",
    "        # simulation part without spin up\n",
    "        var = recom_dates\n",
    "        ind1, ind2 = np.where(var.dates>=var.date_start)[0], np.where(var.dates<=var.date_end)[0]\n",
    "        indices = list(set(ind1) & set(ind2))\n",
    "        \n",
    "        date = var.dates[indices]\n",
    "        \n",
    "        for dt in date:    \n",
    "            # look for corresponding dates\n",
    "            index = np.argmin(abs(np.floor(track.dates)-np.floor(dt)))\n",
    "            lon.append(track.longitude[index]), lat.append(track.latitude[index])\n",
    "            dpth.append(track.depth[index]), nlvl.append(track.nlevels[index])\n",
    "            # store data\n",
    "        long, lati, dept, nlev = np.asarray(lon), np.asarray(lat), np.asarray(dpth), np.asarray(nlvl)\n",
    "        \n",
    "        # manage spin up and store data\n",
    "        npt = len(var.dates)\n",
    "        # spinup (fill with initial conditions)\n",
    "        longitude, latitude = np.zeros(npt) + long[0], np.zeros(npt) + lati[0]\n",
    "        depth, nlevels = np.zeros(npt) + dept[0], np.zeros(npt) + nlev[0]\n",
    "        # actual simulation\n",
    "        longitude[indices], latitude[indices] = long, lati\n",
    "        depth[indices], nlevels[indices] = dept, nlev\n",
    "        \n",
    "        # store data\n",
    "        self.longitude, self.latitude, self.depth, self.nlevels = longitude, latitude, depth, nlevels\n",
    "#\n",
    "simu_data = simulation_data(recom_dates,vmesh, track_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbda2018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Output at 0x7f2e61da7550>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# save data to netcdf file\n",
    "#\n",
    "class Output(object):\n",
    "    def __init__(self, filename, data):\n",
    "        self.write_grid_information(filename,data)\n",
    "        \n",
    "    def write_grid_information(self,filename,data):\n",
    "        # store grid (Lagrangian and vertical) information\n",
    "        ncid = Dataset(filename, \"w\", format=\"NETCDF4\") \n",
    "\n",
    "        ## define dimensionss\n",
    "        ncid.createDimension('time', len(data.dates))\n",
    "        ncid.createDimension('nl', data.nl)\n",
    "        ncid.createDimension('nl1', data.nl-1)\n",
    "        dimnl, dimnl1, dimt = ('nl'), ('nl1'), ('time')\n",
    "\n",
    "        ## create variables\n",
    "        # dates\n",
    "        dt = ncid.createVariable('dates', \"f8\",'time')\n",
    "        \n",
    "        # geo coordinates\n",
    "        lon, lat = ncid.createVariable('longitude', \"f8\",'time'), ncid.createVariable('latitude', \"f8\",'time')\n",
    "        \n",
    "        # vertical mesh\n",
    "        zb, z = ncid.createVariable('zbar', \"f8\",'nl'), ncid.createVariable('Z', \"f8\",'nl1')\n",
    "        \n",
    "        # related depth and number of vertical levels along the track\n",
    "        dpth, nlvl = ncid.createVariable('depth', \"f8\",'time'), ncid.createVariable('nlevels', \"f8\",'time')\n",
    "        \n",
    "        \n",
    "        ## variables attributes\n",
    "        # description\n",
    "        dt.description='dates related to python ordinal dates (reference date 01/01/0001)'\n",
    "        lon.description, lat.description = 'longitude coordinates', 'latitude coordinates'\n",
    "        zb.description, z.description = 'vertical discretization of depth axis (from ' + mesh_type + ' mesh)', 'vertical discretization of depth axis (middle of cells)'\n",
    "        dpth.description, nlvl.description = 'depth (from topography)', 'number of level considered in simulation (according to depth)'\n",
    "        # units\n",
    "        dt.units='days'\n",
    "        lon.units, lat.units = 'degree (east)', 'degree (north)'\n",
    "        zb.units, z.units = 'm', 'm'\n",
    "        dpth.units, nlvl.units = 'm', ''        \n",
    "        \n",
    "        ## fill variables\n",
    "        # dates\n",
    "        ncid['dates'][:] = data.dates\n",
    "        \n",
    "        # geo coordinates\n",
    "        ncid['longitude'][:] , ncid['latitude'][:] =  data.longitude, data.latitude\n",
    "        \n",
    "        # vertical mesh\n",
    "        ncid['zbar'][:] , ncid['Z'][:] = data.zbar, data.Z\n",
    "        \n",
    "        # depth and vertical levels along the track\n",
    "        ncid['depth'][:] , ncid['nlevels'][:] = data.depth, data.nlevels\n",
    "        \n",
    "        #\n",
    "        ncid.close()\n",
    "\n",
    "#\n",
    "Output(filename_output, simu_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f82b53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
